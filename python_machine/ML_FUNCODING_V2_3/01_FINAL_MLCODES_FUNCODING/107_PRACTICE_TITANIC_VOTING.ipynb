{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하지 말아주세요.<br>\n",
    "본 강의를 잘 정리하면, 데이터 분석과 데이터 과학(머신러닝, 인공지능) 모두 가능합니다!<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩</a> 에서 본 강의 기반 최적화된 로드맵도 확인하실 수 있습니다</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('titanic_step4_importance_train.pickle', 'rb') as pickle_filename:\n",
    "    train_importance = pd.read_pickle(pickle_filename)    \n",
    "with open('titanic_step4_importance_test.pickle', 'rb') as pickle_filename:\n",
    "    test_importance = pd.read_pickle(pickle_filename)\n",
    "with open('titanic_step4_importance_train_y.pickle', 'rb') as pickle_filename:\n",
    "    train_answer = pd.read_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 각 모델에서 내부적으로 관련 라이브러리 사용 가능\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier             # 1. K-Nearest Neighbor(KNN)\n",
    "from sklearn.linear_model import LogisticRegression            # 2. Logistic Regression\n",
    "from sklearn.svm import SVC                                    # 3. SVC\n",
    "from sklearn.tree import DecisionTreeClassifier                # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier            # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier              # 6. Extra Tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier        # 7. GBM\n",
    "from sklearn.naive_bayes import GaussianNB                     # 8. GaussianNB\n",
    "from xgboost import XGBClassifier                              # 9. XGBoost\n",
    "from lightgbm import LGBMClassifier                            # 10. LightGBM\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 재트레닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(C=18.288277344191805, penalty='l2', random_state=1)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric = 'logloss',\n",
    "    learning_rate=0.17, \n",
    "    n_estimators=10, \n",
    "    max_depth=6, \n",
    "    min_child_weight=1,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.01,\n",
    "    colsample_bytree=0.85,\n",
    "    subsample=0.9,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "random_model = RandomForestClassifier(\n",
    "    max_depth=None, \n",
    "    max_features=0.8, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=6, \n",
    "    n_estimators=200, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "extra_model = ExtraTreesClassifier(\n",
    "    max_depth=None, \n",
    "    max_features=0.5, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=10, \n",
    "    n_estimators=50, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier\n",
    "- 일종의 앙상블(ensemble) 의 또다른 기법3 으로(기법1은 Bagging, 기법2는 Boosting), 여러 모델들을 기반으로, 투표를 하는 Voting 기법이 있음\n",
    "- 해당 기법을 사용하여 성능이 괜찮은 모델을 기반으로 Voting 을 해서, 또다른 예측 모델을 구성할 수 있음\n",
    "- Voting 기법도 크게 Hard Voting 기법과 Soft Voting 기법이 존재함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting Classifier\n",
    "- 여러 모델이 예측한 분류 중, 가장 많은 모델이 예측한 분류를 선택하는 기법\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/hardvoting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "grid_hard = VotingClassifier(estimators = [\n",
    "        ('Logistic Regression', logreg_model),\n",
    "        ('XGBoost', xgb_model),\n",
    "        ('Random Forest', random_model), \n",
    "        ('Extra Trees', extra_model),\n",
    "    ], voting = 'hard')\n",
    "\n",
    "score = cross_val_score(grid_hard, train_importance, train_answer, cv=5, scoring='accuracy')\n",
    "print(np.mean(score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting Classifier\n",
    "- 여러 모델을 확률로 예측 분류한 후, 예측 확률의 평균을 내어, 확률이 가장 높은 분류를 선택하는 기법\n",
    "\n",
    "<img src=\"https://www.fun-coding.org/00_Images/softvoting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝한 파라미터로 소프트보팅\n",
    "grid_soft = VotingClassifier(estimators = [\n",
    "        ('Logistic Regression', logreg_model),\n",
    "        ('XGBoost', xgb_model),\n",
    "        ('Random Forest', random_model), \n",
    "        ('Extra Trees', extra_model),\n",
    "    ], voting = 'soft')\n",
    "\n",
    "score = cross_val_score(grid_soft, train_importance, train_answer, cv=5, scoring='accuracy')\n",
    "print(np.mean(score)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 제출 테스트\n",
    "> 타이타닉 경진대회는 외부에서, 테스트 데이터에 대한 정답셋을 구할 수 있으므로, 정답셋을 가지고 직접 테스트하기로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('titanic/test.csv')\n",
    "submission = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission['PassengerId'] = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_hard.fit(train_importance, train_answer)\n",
    "#grid_soft.fit(train_importance, train_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"Survived\"] = grid_hard.predict(test_importance)\n",
    "submission = submission.astype('int')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('titanic_predict.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f titanic_predict.csv -m \"Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">수고 많으셨습니다!</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">Kaggle 타이타닉 랭킹: https://www.kaggle.com/c/titanic/leaderboard </font><br><br>  \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">정답셋을 외부에서 찾을 수 있으므로, 스코어가 1 에 가까운 값들은 모두 cheat 라고 봐야 하지만,</font><br>\n",
    "    <font size=\"4em\" style=\"color:#BF360C;\">이러한 경우를 모두 포함하더라도 즉 <b>top 5%</b> 내의 스코어임</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #E65100;background-color:#FFF3E0;padding:10px\">\n",
    "<font size=\"4em\" style=\"font-weight:bold;color:#BF360C;\">큰그림으로 이해하기</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">데이터 예측 기본 활용을 위해, 다음 단계를 패턴화해서, 활용하기</font><br><br>  \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">1. EDA</font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">2. Feature Engineering </font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- 숫자 변환 </font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- 도메인 이해 기반 영향력 있는 컬럼 추가 </font><br>       \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- OneHot Encoding (또는 Label Encoding) </font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;<b>- 참고(추가 설명): 본 단계에서 스케일링 처리도 할 수 있으며, 이 부분은 이후 강의에서 설명드립니다</b></font><br>\n",
    "<font size=\"4em\" style=\"color:#BF360C;\">&nbsp;&nbsp;&nbsp;&nbsp;- 중요도순 Feature Selection </font><br>                \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">3. Hyper Parameter Tuning (Random Search, Grid Search, Bayesian Optimization)</font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">4. VotingClassifier 로 성능이 좋은 모델 기반 추가 모델까지 만든 후</font><br>    \n",
    "<font size=\"4em\" style=\"color:#BF360C;\">5. 최종 훈련 및 예측</font><br>        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하지 말아주세요.<br>\n",
    "본 강의를 잘 정리하면, 데이터 분석과 데이터 과학(머신러닝, 인공지능) 모두 가능합니다!<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩</a> 에서 본 강의 기반 최적화된 로드맵도 확인하실 수 있습니다</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
